{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml as yaml\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "NO_CONFIG_ERR_MSG = \"\"\"No config file found. Root directory is determined by presence of \"config.yaml\" file.\"\"\"\n",
    "\n",
    "original_wd = os.getcwd()\n",
    "\n",
    "# Number of times to move back in directory\n",
    "num_retries = 10\n",
    "for x in range(0, num_retries):\n",
    "    # try to load config file\n",
    "    try:\n",
    "        with open(\"config.yaml\", 'r') as stream:\n",
    "            cfg = yaml.safe_load(stream)\n",
    "    # If not found move back one directory level\n",
    "    except FileNotFoundError:\n",
    "        os.chdir('../')\n",
    "        # If reached the max number of directory levels change to original wd and print error msg\n",
    "        if x+1 == num_retries:\n",
    "            os.chdir(original_wd)\n",
    "            print(NO_CONFIG_ERR_MSG)\n",
    "\n",
    "# Add directory to PATH\n",
    "path = os.getcwd()\n",
    "\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encode the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= [\n",
    " 'WINS_score',\n",
    " 'market_size',\n",
    " 'superteam_flg']\n",
    "target = [\n",
    "    'team_value'\n",
    "]\n",
    "\n",
    "season_on_hot = pd.get_dummies(df['Season']).add_prefix('Season_')\n",
    "\n",
    "X = pd.merge(season_on_hot, df[features], left_index=True, right_index=True)\n",
    "Y = df['team_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'learning_rate': [.001, 0.05, .01], #so called `eta` value\n",
    "              'max_depth': [2, 5, 10, 20],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [.2, .5, 0.8],\n",
    "              'colsample_bytree': [.2, .5, 0.8],\n",
    "              'n_estimators': [5, 50, 500], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [42]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=6, \n",
    "                   cv=5, verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 1158 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=6)]: Done 1620 out of 1620 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=6,\n",
       "       param_grid={'nthread': [4], 'learning_rate': [0.001, 0.05, 0.01], 'max_depth': [2, 5, 10, 20], 'min_child_weight': [11], 'silent': [1], 'subsample': [0.2, 0.5, 0.8], 'colsample_bytree': [0.2, 0.5, 0.8], 'n_estimators': [5, 50, 500], 'missing': [-999], 'seed': [42]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2647353333157255\n",
      "colsample_bytree: 0.8\n",
      "learning_rate: 0.05\n",
      "max_depth: 5\n",
      "min_child_weight: 11\n",
      "missing: -999\n",
      "n_estimators: 500\n",
      "nthread: 4\n",
      "seed: 42\n",
      "silent: 1\n",
      "subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "#trust your CV!\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# test_probs = clf.predict_proba(test[features])[:,1]\n",
    "\n",
    "# sample = pd.read_csv('../input/sample_submission.csv')\n",
    "# sample.QuoteConversion_Flag = test_probs\n",
    "# sample.to_csv(\"xgboost_best_parameter_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 11,\n",
       " 'missing': -999,\n",
       " 'n_estimators': 500,\n",
       " 'nthread': 4,\n",
       " 'seed': 42,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
